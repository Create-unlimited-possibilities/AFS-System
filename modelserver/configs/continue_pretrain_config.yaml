# 继续预训练配置

# 基础模型
base_model: "Qwen/Qwen2.5-14B"
output_path: "/userdata/{user_id}/models/cpt_model"

# 训练配置
training:
  num_epochs: 1
  batch_size: 2
  gradient_accumulation_steps: 4
  learning_rate: 1e-4
  weight_decay: 0.01
  warmup_ratio: 0.03
  max_grad_norm: 1.0
  
  save_steps: 1000
  logging_steps: 50

# 数据配置
data:
  train_path: "/userdata/{user_id}/datasets/continue_pretrain_data.json"
  block_size: 1024
  padding: "max_length"

# 模型配置
model:
  vocab_size: 151936
  hidden_size: 5120
  num_hidden_layers: 28
  num_attention_heads: 16
  intermediate_size: 14336

# 优化器
optimizer:
  type: "AdamW"
  betas: [0.9, 0.999]

# 硬件配置
hardware:
  device: "cuda"
  num_gpus: 1
  mixed_precision: "bf16"
  
# 显存需求
gpu_memory:
  min: "16GB"
  recommended: "24GB"